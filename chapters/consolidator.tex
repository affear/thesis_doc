%!TEX root = ../thesis.tex
%%--------------------------------------------------------------------------
%% NOVA CONSOLIDATOR
%%--------------------------------------------------------------------------

OpenStack already performs virtual machine placement. This is accomplished thanks to its \texttt{nova-scheduler} service. Once a virtual machine is created (or, in certain cases, resized or live migrated) the scheduler decides which of the available compute nodes can host\footnote{The policies by which a node can host or not a virtual machine are defined by the precise filter which scheduler has been equipped with.} the virtual machine (this phase is called \textit{filtering}) and then selects the best\footnote{Again, it depends on which weighter is used.} among them (this phase is called \textit{weighting}).

OpenStack, on the other hand, \emph{does not} perform virtual machine consolidation. Each of the operations on virtual machines are issued by the user that owns them (or by \texttt{Heat} for him/her).

Virtual machine consolidation is a technique by which virtual machines locations on hosts are changed to achieve a better resource utilization in the whole system. Thus, virtual machines are periodically migrated to other hosts if some policy determines that its place is wrong in that precise moment. The policy adopted is determined by the \emph{consolidation algorithm} that is used.

To add virtual machine consolidation to OpenStack we added a service to \texttt{Nova} called \texttt{nova-consolidator}. The new service is implemented in module \code{nova.consolidator} which provides a \code{nova.consolidator.base.BaseConsolidator} class which can be extended to write custom consolidators (see section \ref{sec:cons_base}). We also developed some consolidation algorithms, both custom and taken from the state of the art (see section \ref{sec:cons_algs}).

\section{Consolidator Base}
\label{sec:cons_base}

Almost every service in OpenStack has three main components: the \emph{command}\footnote{In our case, \code{nova.cmd.consolidator}.} (its function \code{main} will be executed at service startup\footnote{When DevStack runs \code{python setup.py install}, \textit{PyPI} generates an executable file placed at \texttt{/usr/local/bin} called \texttt{nova-consolidator} (see note \ref{note:pypi}). It is necessary to make DevStack aware of the new service created to make it install and start it. As a result we had to fork DevStack repository and edit the function \code{start\_nova\_rest} in \texttt{/lib/nova} (see \url{https://github.com/affear/devstack/blob/n-cons/lib/nova}).}); the \emph{manager}\footnote{In our case, \code{nova.consolidator.manager}.}, which contains the service's real logic and the \emph{RPC\footnote{Remote Procedure Call} API}\footnote{In our case, \code{nova.consolidator.rpcapi}}, which is used by OpenStack services to communicate\footnote{\url{https://github.com/affear/nova/tree/n-cons/nova/consolidator}}.

The command basically instantiates a \code{nova.service.Service} object with the name ``\texttt{nova-consolidator}''. The service, in turn, instantiates a \code{nova.consolidator.manager.ConsolidatorManager} object; and starts its RPC server and its \emph{periodic tasks}. As we can see in listing \ref{lst:cons_manager}\footnote{\label{note:cons_code}The code has been properly cut to fit the page and the reader needs.}, \code{ConsolidatorManager} exposes one periodic task which is represented by the \code{consolidate} method.
Its period is defined in \texttt{/etc/nova/nova.conf} file (which can be edited using DevStack. See ~\ref{sub:fakestack_conf}), under the option \texttt{consolidation\_interval}. In the configuration file one must also specify the consolidator class to be used by the manager. When the manager is created it creates the specified \texttt{consolidator\_class} object and periodically calls the method \code{consolidate}. The \code{consolidate} method \emph{delegates} consolidation to the consolidator object, from which it obtains the migrations to be performed. Keep in mind that the consolidator could decide not to return any migration in case they would not improve system status. Once the migrations are obtained, they are applied using \texttt{nova-compute}'s API.

The consolidator class is, by default, \code{nova.consolidator.base.BaseConsolidator} (see listing \ref{lst:cons_base}\footnoteref{note:cons_code}), which does nothing but define a base class to extend with real consolidation algorithms. Its \code{get\_migrations} method, in fact, returns an empty list of migrations.

\code{consolidate} method obtains a snapshot of the system (see subsection \ref{sub:cons_obj} for snapshot object details) and passes it to the \code{get\_migrations} method. \code{get\_migrations} will implement the desired consolidation algorithm. Eventually, a transitive closure on migrations is applied\footnote{If instance $I$ is moved first to host $A$ and then to host $B$; instance $I$ is only moved to host $B$.} and the migrations are returned to the manager.

\begin{lstlisting}[
	float,
	language=python,
	caption={Code for \texttt{nova.consolidator.manager.ConsolidatorManager}},
	label={lst:cons_manager},
	tabsize=2
]
class ConsolidatorManager(manager.Manager):

	def __init__(self, *args, **kwargs):
		self.compute_api = compute_api.API()
		self.consolidator = importutils.\
			import_class(CONF.consolidator_class)()
		# lines skipped

	@periodic_task.\
		periodic_task(spacing=CONF.consolidation_interval)
	def consolidate(self, ctxt):
		migrations = self.consolidator.consolidate(ctxt)
		for m in migrations:
			self._do_live_migrate(ctxt, m)

	def _do_live_migrate(self, ctxt, migration):
		instance = migration.instance
		host_name = migration.host.host
		# exception catching skipped
		self.compute_api.live_migrate(
			ctxt, instance,
			False, False, host_name
		)
\end{lstlisting}

\begin{lstlisting}[
	float,
	language=python,
	caption={Code for \texttt{nova.consolidator.base.BaseConsolidator}},
	label={lst:cons_base},
	tabsize=2
]
class BaseConsolidator(object):

	class Migration(object):
		def __init__(self, instance, host):
			super(BaseConsolidator.Migration, self).__init__()
			self.instance = instance
			self.host = host

	# _transitive_closure method
	# implementation skipped

	def consolidate(self, ctxt):
		snapshot = Snapshot(ctxt)
		migs = self.get_migrations(snapshot)
		return self._transitive_closure(migs)

	def get_migrations(self, snapshot):
		return []
\end{lstlisting}

\subsection{Objects}
\label{sub:cons_obj}
We thought that it was not a good idea to ask the user to learn and understand OpenStack's complex database APIs.
Due to this fact, we developed \code{nova.consolidator.objects}, a module that defines the abstraction of system snapshots used in method \code{get\_migrations}. The module provides the class \code{nova.consolidator.objects.Snapshot}. A \code{Snapshot} object offers attributes to access all information about the system, such as the currently active nodes, and the currently active instances (also per node). The \code{Snapshot} is renewed at each consolidation cycle. Attributes are lazily obtained on their first call; subsequent invocations won't refresh snapshot's state. The Snapshot is, thus, entirely cached: when an instance or a compute node is asked and returned, it will not be queried again on OpenStack's database. Its status will always be \emph{frozen} at the moment the first query has been performed. To refresh a \code{Snapshot} it is necessary to create a new \code{Snapshot} object.

In detail, a \code{Snapshot} object offers all instances (\code{instances} attribute); running instances (\code{instances\_running} attribute); both those instances that are migratable and those that are not\footnote{According to us, an instance is \emph{migratable} when its state is \texttt{ACTIVE} and its power state is \texttt{RUNNING}.} (\code{instances\_migrable} and \code{instances\_not\_migrable} attributes, respectively) and active nodes (\code{nodes} attribute). Instances are \code{nova.objects.instance.Instance}\footnote{\url{https://github.com/openstack/nova/blob/master/nova/objects/instance.py}} objects; nodes are wrappers for \code{nova.objects.compute\_node.ComputeNode}\footnote{\url{https://github.com/openstack/nova/blob/master/nova/objects/compute_node.py}} objects, which add the possibility to get all, running, intances that are migratable and not, per compute node.

In any case, the developer does not instantiate \code{Snapshot} objects: this is up to \code{consolidate} method, which already instantiates and passes the current system snapshot to method \code{get\_migrations}. \code{get\_migrations} is therefore the \emph{only} method that needs to be overridden by the user in a custom consolidator class.

In listing \ref{lst:cons_snapshot} we provide an example of using a \code{Snapshot} in a python script.

\begin{lstlisting}[
	float,
	language=python,
	caption={An example of using a \texttt{Snapshot} object},
	label={lst:cons_snapshot},
	tabsize=2
]
from nova import config, objects, context
from nova.consolidator.objects import Snapshot

# Init operations
config.parse_args('')
objects.register_all()
ctxt = context.get_admin_context()

# Using the Snapshot
s = Snapshot(ctxt)
nodes = snapshot.nodes # all compute nodes
node = nodes[0] # the first node
instances = node.instances # all instances on that node (list)
print node.vcpu
print node.id
print instances[0].flavor
# `node` has all attributes as
# nova.objects.compute_node.ComputeNode has,
# as well as `instances[0]` has all attributes as
# nova.objects.instance.Instance has.

nodes_new = snapshot.nodes
# nodes are not refreshed because they are cached!
assert nodes == nodes_new # evaluates to True
\end{lstlisting}

\section{Algorithms}
\label{sec:cons_algs}
In this section, we explain the consolidation algorithms that we implemented in our \texttt{nova-consolidator}. Each of the proposed algorithms is run inside a consolidator class that inherits from \code{nova.consolidator.base.BaseConsolidator}.

\subsection{Random Algorithm}
\label{sub:algs_rnd}
The first algorithm we implemented is a random one\footnote{\url{https://github.com/affear/nova/blob/n-cons/nova/consolidator/base.py}}. This algorithm was implemented for testing purposes and to see if randomization could bring improvement in resource optimization, given that virtual machines are never moved in OpenStack\footnote{Except for when a user decides to, or on a resize call. When a virtual machine is resized to a flavor which is too big for the current host, it is migrated to a suitable one.}.

The algorithm needs to be configured with a percentage of instances to migrate to other compute nodes. Instances are randomly chosen from hosts' migratable instances and their destinations are randomly chosen among remaining hosts. Choices dp not take into account host suitability. The algorithm doesn't rely on the fact that migrations will be applied. If a migration fails, due to resource usage problems, it is not a problem.

The random algorithm is highlighted in in listing \ref{lst:rnd_alg}\footnoteref{note:cons_code}.

\begin{lstlisting}[
	float,
	language=python,
	caption={Code for random algorithm},
	label={lst:rnd_alg},
	tabsize=2
]
def get_migrations(self, snapshot):
	nodes = snapshot.nodes
	no_nodes = len(nodes)
	migration_percentage = float(CONF.consolidator.migration_percentage) / 100
	no_inst = len(snapshot.instances_migrable)
	no_inst_migrate = int(no_inst * migration_percentage)

	# if no_inst_migrate == 0
	# or no_nodes < 2, then
	# return empty list.
	# Cannot migrate.

	migs = []
	while no_inst_migrate > 0:
		nodes_cpy = list(nodes) # copy nodes list

		from_host = choose_host(nodes_cpy)
		# choose_host code is skipped.
		# The chosen node is randomly chosen
		# taking into account that it has to host
		# at least one instance.

		inst_on_host = from_host.instances_migrable
		no_inst_on_host = len(inst_on_host)

		top_bound = min(no_inst_on_host, no_inst_migrate)
		n = random.randint(1, top_bound)
		no_inst_migrate -= n

		instances = random.sample(inst_on_host, n)
		nodes_cpy.remove(from_host) # do not choose same host
		to_host = random.choice(nodes_cpy)
		for i in instances:
			migs.append(self.Migration(i, to_host))

	return migs
\end{lstlisting}

\subsection{Genetic Algorithm}
\label{sub:algs_ga}
The idea to use a genetic algorithm to solve virtual machine consolidation problem is taken from the state of the art (see section \ref{sec:sota_ga}), although we heavily revisited it\footnote{https://github.com/affear/nova/tree/n-cons/nova/consolidator/ga}.

Our genetic algorithm uses a list as chromosome structure. Each element of the list (a gene) is considered to be a migratable instance, and its value is the hostname of the compute node that will host the instance. At first, we developed the algorithm as a ``standard'' genetic algorithm. So, it provided a crossover step. A child generated by crossover is considered \emph{unhealthy} when it violates system constraints (instances on a node exceed its vCPU, memory or disk capacity). After some simulations we realized that $100\%$ of the children generated were unhealthy. Suddenly, we realized that the probability of generating a healthy child was close to zero because of the tightness of system constraints. Thus, the crossover step became useless and we decided to turn it into a massive mutation. In the crossover we would chose\footnote{Chromosome are chosen among the whole population using a specific selection algorithm.} two chromosomes, the father and the mother, and cross them\footnote{We performed a single point crossover. See \url{http://en.wikipedia.org/wiki/Crossover\_\%28genetic\_algorithm\%29\#One-point\_crossover}.}; now we only choose one chromosome and massively\footnote{We change the value of a high percentage of its genes.} mutate it.

The algorithm is configurable in all of its aspects:
\begin{description}
	\item[prob\_mutation] (Defaults to $0.8$) The probability to apply mutation on a chromosome.
	\item[mutation\_perc] (Defaults to $10$) The percentage of genes to be mutated in a chromosome, once mutation is decided to be applied.
	\item[selection\_algorithm] \hfill \\
	(Defaults to \code{nova.consolidator.ga.functions.RouletteSelection}) The selection algorithm used. The selection algorithm plays its role when it's time to decide which chromosomes to cross (in our case, mutate) to generate a new child to add to the population (an implementation of tournament selection is provided in \code{nova.consolidator.ga.functions.TournamentSelection}).
	\item[fitness\_function] \hfill \\
	(Defaults to \code{nova.consolidator.ga.functions.NoNodesFitnessFunction}) The Fitness function establishes how much the chromosome fits the desired solution (see listing \ref{lst:ga_fitness} for \code{NoNodesFitnessFunction} implementation).
	\item[population\_size] (Defaults to $500$) The size of the population.
	\item[epoch\_limit] (Defaults to $100$) The number of epochs after which the algorithm stops.
	\item[elitism\_perc] (Defaults to $0$) The percentage of chromosomes that will pass to the next epoch. The number \texttt{N} of elite chromosomes is determined from this option and the \texttt{population\_size}. At each step the best \texttt{N} chromosomes (according to the fitness function used) will pass to the next epoch.
\end{description}

There is another option which is \texttt{best} (defaults to $False$). After running some simulations, we discovered that most of the epochs run without improving the fitness of the best chromosome, meaning we spent a lot of time generating useless children. To overcome this problem we revisited the mutation. When we apply mutation we change a gene's value and maintain the chromosomes' validities. Changing a gene's value means moving an instance to another compute node. The other compute node, normally, is chosen randomly among suitable nodes\footnote{Nodes that, hosting the machine, will not exceed their capacity in terms of vCPUs, memory and disk.}. When \texttt{best} is set to $True$, the other compute node is no longer chosen randomly; instead we choose the best node\footnote{The most busy compute node.} among the suitable compute nodes. With this change in mutation logic, it turns out that the best chromosome generated in the very first epoch will almost never be exceeded by another one. Thus, this variant, truncates to number of epochs to $1$. The ``best'' variant is something vaguely similar to a genetic algorithm because there is no evolution except from the selection logic and the mutation.

In algorithm \ref{alg:ga} we provide a high-level pseudo-code for our genetic algorithm.

\begin{lstlisting}[
	float,
	language=python,
	caption={Code for \texttt{NoNodesFitnessFunction}},
	label={lst:ga_fitness},
	tabsize=2
]
class NoNodesFitnessFunction(FitnessFunction):
  # The higher the less nodes are used:
  #  - no_nodes = 1: fitness = 1
  #  - no_nodes -> infinite: fitness -> 0

  def get(self, chromosome):
    return float(1) / len(set(chromosome))
\end{lstlisting}

\begin{algorithm}[H]
\caption{Pseudo-code for our genetic algorithm}
\label{alg:ga}
\begin{algorithmic}[0]
	\State population = \texttt{population\_size} random generated valid chromosomes
	\State epoch\_count = 0
	\State

	\Procedure{new\_chromosome}{}\Comment{Returns a new chromosome}
		\State Select a chromosome from population using \texttt{selection\_algorithm}
		\State Mutate the chromosome with probability \texttt{mutation\_prob}
		\State Return the chromosome obtained
	\EndProcedure
	\State
	\Procedure{next}{}\Comment{Returns next population}
		\State Take the elite from current population (\texttt{elitism\_perc})
		\State Add it to new population
		\While{new population is not as big as \texttt{population\_size}}
			\State Add to new population the result of new\_chromosome procedure
		\EndWhile
	\EndProcedure
	\State

	\While{epoch\_count is less than \texttt{epoch\_limit}}
		\State population = next()
		\State Increment epoch\_count
	\EndWhile

	\State
	\State return population
\end{algorithmic}
\end{algorithm}

\subsection{Holistic Algorithm}
\label{sub:algs_holistic}
We also provide a holistic algorithm\footnote{\url{https://github.com/affear/nova/tree/n-cons/nova/consolidator/holistic}} taken from the state of the art (see section \ref{sec:sota_holistic}).

The algorithm takes the least loaded compute node and tries to move all its instances to the most loaded node that can host them. The algorithm tries to move instances from the biggest to the smallest (in terms of resource usage). When finished with the least loaded node, the algorithm examines the second least loaded node and so on, until all nodes are examined.

In algorithm \ref{alg:holistic} we provide the pseudo-code for the holistic algorithm.

\begin{algorithm}[H]
\caption{Pseudo-code for holistic algorithm}
\label{alg:holistic}
\begin{algorithmic}[0]
	\State nodes = nodes from given snapshot
	\State no\_nodes = number of nodes given in snapshot
	\State new\_state = mappings (instance: node)
	\State
	\ForAll{node in nodes}
		\State node = least loaded node
		\State
		\If{node has no instances}
			\State continue
		\EndIf
		\State
		\State Sort node's migratable instances from biggest to smallest
		\State
		\ForAll{instance in node's instances}
			\State to\_node = most loaded node that can host instance
			\If{to\_node doesn't exist}
				\State continue
			\EndIf
			\State add mapping (instance: to\_node) to new\_state
		\EndFor
	\EndFor
	\State
	\State return new\_state
\end{algorithmic}
\end{algorithm}