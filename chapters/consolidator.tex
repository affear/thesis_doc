%!TEX root = ../thesis.tex
%%--------------------------------------------------------------------------
%% NOVA CONSOLIDATOR
%%--------------------------------------------------------------------------

OpenStack already performs virtual machine placement. This is accomplished thanks to its \texttt{nova-scheduler} service. Once a virtual machine is created (or, in certain cases, resized or live migrated) the scheduler decides which of the available compute nodes can host\footnote{The policies by which a node can host or not a virtual machine are defined by the precise filter which scheduler has been equipped with.} the virtual machine (this phase is called \textit{filtering}) and then selects the best\footnote{Again, it depends on which weighter is used.} among them (this phase is called \textit{weighting}).

OpenStack \emph{doesn't} perform virtual machine consolidation. Each of the operations on virtual machines are issued by the user that owns them (or by \texttt{Heat} for him/her).

Virtual machine consolidation is a technique by which virtual machines locations on hosts are changed to achieve a better resource utilization in the whole system. Thus, virtual machines are periodically live (or cold) migrated to other hosts if some policy determines that its place is the wrong in that precise moment. The policy adopted is determined by the \emph{consolidation algorithm} used.

To add virtual machine consolidation feature to OpenStack we added a service to \texttt{Nova} called \texttt{nova-consolidator}. The new service is implemented in module \code{nova.consolidator} which provides a \code{nova.consolidator.base.BaseConsolidator} class which can be extended to write custom consolidators (see section \ref{sec:cons_base}) and some consolidation algorithms, both custom and taken from the state of the art (see section \ref{sec:cons_algs}).

\section{Consolidator Base}
\label{sec:cons_base}

Almost every service into OpenStack has three main components, the \emph{command}\footnote{In our case, \code{nova.cmd.consolidator}.} (its function \code{main} will be executed at service startup\footnote{When DevStack runs \code{python setup.py install}, \textit{PyPI} generates an executable file placed at \texttt{/usr/local/bin} called \texttt{nova-consolidator} (see note \ref{note:pypi}). It is necessary to make DevStack aware of the new service created to make it install and start it. As a result we had to fork DevStack repository and edit the function \code{start\_nova\_rest} in \texttt{/lib/nova} (see \url{https://github.com/affear/devstack/blob/n-cons/lib/nova}).}); the \emph{manager}\footnote{In our case, \code{nova.consolidator.manager}.}, which contains the real logic of the service and the \emph{RPC\footnote{Remote Procedure Call} API}\footnote{In our case, \code{nova.consolidator.rpcapi}}, which is used among OpenStack services to communicate\footnote{\url{https://github.com/affear/nova/tree/n-cons/nova/consolidator}}.

The command basically instantiates a \code{nova.service.Service} object with name ``\texttt{nova-consolidator}''. The service, in turn, instantiates a \code{nova.consolidator.manager.ConsolidatorManager} object; starts its RPC server and its \emph{periodic tasks}. As we can see in listing \ref{lst:cons_manager}\footnote{\label{note:cons_code}The code has been properly cut to fit the page and the reader needs.}, \code{ConsolidatorManager} exposes only one periodic task which is \code{consolidate} method.
Its period is defined in \texttt{/etc/nova/nova.conf} file (which can be edited using DevStack. See ~\ref{sub:fakestack_conf}) in option \texttt{consolidation\_interval} as well as the consolidator class used by the manager. When the manager is created a consolidator object is obtained using the \texttt{consolidator\_class} provided. Then, periodically, \code{consolidate} task is invoked. \code{consolidate} function \emph{delegates} consolidation to the consolidator object obtaining the necessary migrations to be performed. Once migrations are obtained, they are applied using \texttt{nova-compute}'s API.

The consolidator class is, by default, \code{nova.consolidator.base.BaseConsolidator} (see listing \ref{lst:cons_base}\footnoteref{note:cons_code}), which does nothing but defining a base class to be extended with real consolidation algorithms. Its \code{get\_migrations} method, in fact, returns an empty list of migrations. The most important method in \code{BaseConsolidator} is \code{consolidate}, which is the method the manager delegates consolidation to.

This method creates a snapshot of the system (see \ref{sub:cons_obj}) and passes it to \code{get\_migrations} method. \code{get\_migrations} will implement the consolidation algorithm desired. Eventually, a transitive closure on migrations is applied\footnote{If instance $I$ is moved first to host $A$ and then to host $B$; instance $I$ is only moved to host $B$.} and the migrations are returned to the manager.

\begin{lstlisting}[
	float,
	language=python,
	caption={Code for \texttt{nova.consolidator.manager.ConsolidatorManager}},
	label={lst:cons_manager},
	tabsize=2
]
class ConsolidatorManager(manager.Manager):

	def __init__(self, *args, **kwargs):
		self.compute_api = compute_api.API()
		self.consolidator = importutils.\
			import_class(CONF.consolidator_class)()
		# lines skipped

	@periodic_task.\
		periodic_task(spacing=CONF.consolidation_interval)
	def consolidate(self, ctxt):
		migrations = self.consolidator.consolidate(ctxt)
		for m in migrations:
			self._do_live_migrate(ctxt, m)

	def _do_live_migrate(self, ctxt, migration):
		instance = migration.instance
		host_name = migration.host.host
		# exception catching skipped
		self.compute_api.live_migrate(
			ctxt, instance,
			False, False, host_name
		)
\end{lstlisting}

\begin{lstlisting}[
	float,
	language=python,
	caption={Code for \texttt{nova.consolidator.base.BaseConsolidator}},
	label={lst:cons_base},
	tabsize=2
]
class BaseConsolidator(object):

	class Migration(object):
		def __init__(self, instance, host):
			super(BaseConsolidator.Migration, self).__init__()
			self.instance = instance
			self.host = host

	# _transitive_closure method
	# implementation skipped

	def consolidate(self, ctxt):
		snapshot = Snapshot(ctxt)
		migs = self.get_migrations(snapshot)
		return self._transitive_closure(migs)

	def get_migrations(self, snapshot):
		return []
\end{lstlisting}

\subsection{Objects}
\label{sub:cons_obj}
We thought that it wouldn't have been fair to leave to the user the duty to learn and understand OpenStack's complex database APIs.
Due to this fact, we developed \code{nova.consolidator.objects}, which is a module that defines an abstraction of system snapshot to be used in method \code{get\_migrations} by developers. The module provides the class \code{nova.consolidator.objects.Snapshot}. A \code{Snapshot} object offers attributes to access all information about the system, such as current active nodes and instances both for each node and, generally, in the system itself. The \code{Snapshot} is thought to be renewed at each consolidation cycle. So, any attribute is lazily obtained on its first call: subsequent invocations of that attribute won't refresh snapshot's state. The Snapshot is, thus, entirely cached\footnote{Once an instance or a compute node is obtained it will not be queried again on OpenStack's database. Its status is \emph{frozen} at the moment the first query has been performed. To refresh a \code{Snapshot} it is necessary to create a new \code{Snapshot} object.}.

In detail, a \code{Snapshot} object offers active nodes (\code{nodes} attribute) and all, running, migratable\footnote{According to us, an instance is \emph{migratable} when its state is \texttt{ACTIVE} and its power state id \texttt{RUNNING}.} and not instances. Instances are \code{nova.objects.instance.Instance}\footnote{\url{https://github.com/openstack/nova/blob/master/nova/objects/instance.py}} objects; nodes are wrappers for \code{nova.objects.compute\_node.ComputeNode}\footnote{\url{https://github.com/openstack/nova/blob/master/nova/objects/compute_node.py}} objects, which add the possibility to get all, running, migratable and not instances per compute node.

In any case, the developer is not thought to instantiate \code{Snapshot} objects, because this is up to \code{consolidate} method, which already instantiates and passes the current system snapshot to method \code{get\_migrations}, which is the \emph{only} method which needs to be overridden by the user in a custom consolidator class.

In listing \ref{lst:cons_snapshot} we provide an example of using a \code{Snapshot} in a python script.

\begin{lstlisting}[
	float,
	language=python,
	caption={An example of using a \texttt{Snapshot} object},
	label={lst:cons_snapshot},
	tabsize=2
]
from nova import config, objects, context
from nova.consolidator.objects import Snapshot

# Init operations
config.parse_args('')
objects.register_all()
ctxt = context.get_admin_context()

# Using the Snapshot
s = Snapshot(ctxt)
nodes = snapshot.nodes # all compute nodes
node = nodes[0] # the first node
instances = node.instances # all instances on that node (list)
print node.vcpu
print node.id
print instances[0].flavor
# `node` has all attributes as
# nova.objects.compute_node.ComputeNode has,
# as well as `instances[0]` has all attributes as
# nova.objects.instance.Instance has.

nodes_new = snapshot.nodes
# nodes are not refreshed because they are cached!
assert nodes == nodes_new # evaluates to True
\end{lstlisting}

\section{Algorithms}
\label{sec:cons_algs}
In this section, we explain in detail consolidation algorithms that we implemented in our \texttt{nova-consolidator}. Each of the algorithms proposed is run inside a consolidator class that inherits from \code{nova.consolidator.base.BaseConsolidator}, inside \code{get\_migrations} method.

\subsection{Random Algorithm}
\label{sub:algs_rnd}
The first algorithm we implemented is the random one\footnote{\url{https://github.com/affear/nova/blob/n-cons/nova/consolidator/base.py}}. This algorithm was implemented for testing purpose and to see if even randomization could bring improvement in resource optimization, given that virtual machines are never moved in OpenStack\footnote{Except for when a user decides to, or on a resize call. When a virtual machine is resized to a flavor which is too big for the current host, it is migrated to a suitable one.}.

The algorithm takes, by configuration, a percentage of migratable instances to be migrated to other compute nodes. Instances are randomly chosen from hosts and their destination is randomly chosen among remaining hosts. Choices are not taken taking into account host suitability. The algorithm by itself doesn't rely on the fact that migrations will be applied. If a migration fails, due to resource usage problems, it is not a problem.

Random algorithm is highlighted in in listing \ref{lst:rnd_alg}\footnoteref{note:cons_code}.

\begin{lstlisting}[
	float,
	language=python,
	caption={Code for random algorithm},
	label={lst:rnd_alg},
	tabsize=2
]
def get_migrations(self, snapshot):
	nodes = snapshot.nodes
	no_nodes = len(nodes)
	migration_percentage = float(CONF.consolidator.migration_percentage) / 100
	no_inst = len(snapshot.instances_migrable)
	no_inst_migrate = int(no_inst * migration_percentage)

	# if no_inst_migrate == 0
	# or no_nodes < 2, then
	# return empty list.
	# Cannot migrate.

	migs = []
	while no_inst_migrate > 0:
		nodes_cpy = list(nodes) # copy nodes list

		from_host = choose_host(nodes_cpy)
		# choose_host code is skipped.
		# The chosen node is randomly chosen
		# taking into account that it has to host
		# at least one instance.

		inst_on_host = from_host.instances_migrable
		no_inst_on_host = len(inst_on_host)

		top_bound = min(no_inst_on_host, no_inst_migrate)
		n = random.randint(1, top_bound)
		no_inst_migrate -= n

		instances = random.sample(inst_on_host, n)
		nodes_cpy.remove(from_host) # do not choose same host
		to_host = random.choice(nodes_cpy)
		for i in instances:
			migs.append(self.Migration(i, to_host))

	return migs
\end{lstlisting}

\subsection{Genetic Algorithm}
\label{sub:algs_ga}
The idea to use a genetic algorithm to solve virtual machine consolidation problem is taken from the state of the art (see section \ref{sec:sota_ga}), although heavily revisited from us\footnote{https://github.com/affear/nova/tree/n-cons/nova/consolidator/ga}.

Our genetic algorithm uses a list as chromosome structure. Each element of the list (a gene) is considered as a migratable instance an its value is the hostname of the compute node that will host the instance. At first, we developed the algorithm as a ``standard'' genetic algorithm. So, it provided a crossover step. After some simulation we realized that $100\%$ of the children generated were unhealthy\footnote{A child is considered unhealthy when it violates system constraints. For example, instances on a node exceed its memory capacity.}. Suddenly, we realized that the probability of generating a healthy child was close to zero because of the tightness of system constraints. Thus, the crossover step became useless and we decided to turn it into a massive mutation. While in crossover we chose\footnote{Chromosome are chosen among the whole population using a specific selection algorithm.} two chromosomes, father and mother, and crossed them; now we choose only one chromosome and massively\footnote{We change the value of an high percentage of its genes.} mutate it.

The algorithm is configurable in all of its aspects:
\begin{description}
	\item[prob\_mutation] (Defaults to $0.8$) The probability to apply mutation on a chromosome.
	\item[mutation\_perc] (Defaults to $10$) The percentage of the genes to be mutated in a chromosome, once mutation is decided to be applied.
	\item[selection\_algorithm] (Defaults to \code{nova.consolidator.ga.functions.RouletteSelection}) The selection algorithm used. Selection algorithm plays its role when its time to decide which chromosomes to cross (in our case, mutate) to generate a new children to add to the new population (an implementation of tournament selection is provided in \code{nova.consolidator.ga.functions.TournamentSelection}).
	\item[fitness\_function] (Defaults to \code{nova.consolidator.ga.functions.NoNodesFitnessFunction}) Fitness function is the one thats establishes how much the chromosome fits the solution wanted (see listing \ref{lst:ga_fitness} for \code{NoNodesFitnessFunction} implementation).
	\item[population\_size] (Defaults to $500$) The size of the population.
	\item[epoch\_limit] (Defaults to $100$) The number of epochs above what the algorithm stops.
	\item[elitism\_perc] (Defaults to $0$) The percentage of chromosomes that will pass to the next epoch. The number \texttt{N} of elite chromosomes is determined from this option and \texttt{population\_size} option. At each step the best \texttt{N} chromosomes (according to the fitness function used) will pass to the next epoch.
\end{description}

There is another option which is \texttt{best} (defaults to $False$). After running some simulation, we discovered that most of the epochs run without improving the fitness of the best chromosome and so we spent time in generating useless children. To overcome this problem we revisited mutation. Mutation is applied changing a gene's value and maintaining the chromosomes validity. To change a gene value means moving an instance to another compute node. The other compute node, normally, is chosen randomly among suitable nodes\footnote{Nodes that, hosting the machine, will not exceed their capacity in terms of vCPUs, memory and disk.}. When \texttt{best} is set to $True$, the other compute node is no more chosen randomly but as the best\footnote{The most busy compute node.} among suitable compute nodes. With this change in mutation logic, it turns out that the best chromosome generated in the very first epoch will almost never be exceeded by another one. Thus, this variant, truncates to number of epochs to $1$. The ``best'' variant is something vaguely similar to a genetic algorithm because there is no evolution except from selection logic and mutation.

In algorithm \ref{alg:ga} we provide a high-level pseudo-code for our genetic algorithm.

\begin{lstlisting}[
	float,
	language=python,
	caption={Code for \texttt{NoNodesFitnessFunction}},
	label={lst:ga_fitness},
	tabsize=2
]
class NoNodesFitnessFunction(FitnessFunction):
  # The higher the less nodes are used:
  #  - no_nodes = 1: fitness = 1
  #  - no_nodes -> infinite: fitness -> 0

  def get(self, chromosome):
    return float(1) / len(set(chromosome))
\end{lstlisting}

\begin{algorithm}[H]
\caption{Pseudo-code for our genetic algorithm}
\label{alg:ga}
\begin{algorithmic}[0]
	\State population = \texttt{population\_size} random generated valid chromosomes
	\State epoch\_count = 0
	\State

	\Procedure{new\_chromosome}{}\Comment{Returns a new chromosome}
		\State Select a chromosome from population using \texttt{selection\_algorithm}
		\State Mutate the chromosome with probability \texttt{mutation\_prob}
		\State Return the chromosome obtained
	\EndProcedure
	\State
	\Procedure{next}{}\Comment{Returns next population}
		\State Take the elite from current population (\texttt{elitism\_perc})
		\State Add it to new population
		\While{new population is not as big as \texttt{population\_size}}
			\State Add to new population the result of new\_chromosome procedure
		\EndWhile
	\EndProcedure
	\State

	\While{epoch\_count is less than \texttt{epoch\_limit}}
		\State population = next()
		\State Increment epoch\_count
	\EndWhile

	\State
	\State return population
\end{algorithmic}
\end{algorithm}

\subsection{Holistic Algorithm}
\label{sub:algs_holistic}
As well as genetic algorithm, holistic algorithm\footnote{\url{https://github.com/affear/nova/tree/n-cons/nova/consolidator/holistic}} is taken from the state of the art (see \ref{sec:sota_holistic}). In algorithm \ref{alg:holistic} we provide a high-level pseudo-code for holistic algorithm.

\begin{algorithm}[H]
\caption{Pseudo-code for holistic algorithm}
\label{alg:holistic}
\begin{algorithmic}[0]
	\State nodes = nodes from given snapshot
	\State no\_nodes = number of nodes given in snapshot
	\State new\_state = mappings (instance: node)
	\State
	\ForAll{node in nodes}
		\State node = least loaded node
		\State
		\If{node has no instances}
			\State continue
		\EndIf
		\State
		\State Sort node's migratable instances from biggest to smallest
		\State
		\ForAll{instance in node's instances}
			\State to\_node = most loaded node that can host instance
			\If{to\_node doesn't exist}
				\State continue
			\EndIf
			\State add mapping (instance: to\_node) to new\_state
		\EndFor
	\EndFor
	\State
	\State return new\_state
\end{algorithmic}
\end{algorithm}